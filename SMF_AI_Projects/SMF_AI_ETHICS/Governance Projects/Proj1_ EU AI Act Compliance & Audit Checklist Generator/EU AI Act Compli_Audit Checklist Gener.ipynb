{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNRUzZdqrPoDd7DlToXQoZ1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9Ff3KU8g1IsX"},"outputs":[],"source":["# Governance Project 1: EU AI Act Compliance & Audit Checklist Generator\n","\n","# Step 1: Define AI system metadata (example project: Hiring Bias Model)\n","ai_system = {\n","    \"name\": \"Gender Bias in Hiring AI\",\n","    \"use_case\": \"Resume shortlisting\",\n","    \"risk_level\": \"High Risk (per EU AI Act - Annex III)\",\n","    \"sensitive_data\": True,\n","    \"automated_decision\": True,\n","    \"explainability_available\": True,\n","    \"bias_mitigated\": True,\n","    \"fairness_metric\": \"Demographic Parity\",\n","    \"dpd_value\": 0.6,\n","    \"accuracy\": 0.90,\n","    \"explainability_tool\": \"SHAP\",\n","    \"developer\": \"SoulMindFusion Ethical AI Lab\"\n","}\n","\n","# Step 2: Define EU AI Act-aligned governance checklist\n","governance_checklist = [\n","    (\"Risk Classification (High Risk AI)\", ai_system[\"risk_level\"].startswith(\"High\")),\n","    (\"Uses Sensitive Data\", ai_system[\"sensitive_data\"]),\n","    (\"Automated Decision-Making Enabled\", ai_system[\"automated_decision\"]),\n","    (\"Bias Detection Implemented\", True),\n","    (\"Bias Mitigation Applied\", ai_system[\"bias_mitigated\"]),\n","    (\"Explainability Provided\", ai_system[\"explainability_available\"]),\n","    (\"Audit Trail Available\", True),\n","    (\"Model Performance Documented\", ai_system[\"accuracy\"] >= 0.8),\n","    (\"Fairness Metrics Reported\", ai_system[\"dpd_value\"] <= 0.6)\n","]\n","\n","# Step 3: Display compliance summary\n","print(\"\\nEU AI Act Governance Checklist for:\", ai_system[\"name\"])\n","compliance_passed = 0\n","for item, status in governance_checklist:\n","    status_text = \"✅\" if status else \"❌\"\n","    print(f\"- {item}: {status_text}\")\n","    compliance_passed += int(status)\n","\n","total = len(governance_checklist)\n","print(f\"\\nGovernance Score: {compliance_passed}/{total} checks passed\")\n","\n","# Step 4: Governance Grade\n","if compliance_passed == total:\n","    grade = \"A+ (Fully Compliant)\"\n","elif compliance_passed >= total * 0.7:\n","    grade = \"B (Mostly Compliant)\"\n","else:\n","    grade = \"C (Needs Governance Fixes)\"\n","\n","print(\"Governance Grade:\", grade)\n","\n","# Step 5: Output audit summary (dict format)\n","audit_summary = {\n","    \"Project\": ai_system[\"name\"],\n","    \"Use Case\": ai_system[\"use_case\"],\n","    \"Developer\": ai_system[\"developer\"],\n","    \"Risk\": ai_system[\"risk_level\"],\n","    \"Compliance Score\": f\"{compliance_passed}/{total}\",\n","    \"Grade\": grade,\n","    \"Bias Metric\": ai_system[\"fairness_metric\"],\n","    \"DPD Value\": ai_system[\"dpd_value\"],\n","    \"Accuracy\": ai_system[\"accuracy\"],\n","    \"Explainability Tool\": ai_system[\"explainability_tool\"]\n","}\n","\n","# Optional: Export as JSON\n","import json\n","with open(\"audit_summary.json\", \"w\") as f:\n","    json.dump(audit_summary, f, indent=4)\n","\n","print(\"\\nAudit summary exported as 'audit_summary.json'\")\n"]}]}