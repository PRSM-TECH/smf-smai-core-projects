{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNS9K4OIZHSvoCnlwhrHEv7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ML-xuzJLTloG"},"outputs":[],"source":["# Project 2: Racial Bias in Loan Approvals â€“ Decision Tree\n","\n","# Step 1: Install necessary libraries\n","!pip install fairlearn --quiet\n","\n","# Step 2: Import libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from fairlearn.metrics import MetricFrame, equalized_odds_difference\n","\n","# Step 3: Generate synthetic dataset (biased by race)\n","np.random.seed(42)\n","size = 5000  # 5000 loan applications\n","income = np.random.normal(50000, 15000, size)\n","credit_score = np.random.normal(700, 50, size)\n","race = np.random.choice([\"White\", \"Black\"], size=size, p=[0.7, 0.3])  # Imbalance in race\n","\n","# Simulate loan approval with bias against \"Black\"\n","approved = (income + credit_score - (race == \"Black\") * 2000 + np.random.randn(size) * 1000) > 75000\n","approved = approved.astype(int)\n","\n","# Step 4: Create DataFrame\n","df_loan = pd.DataFrame({\n","    \"Income\": income,\n","    \"CreditScore\": credit_score,\n","    \"Race\": race,\n","    \"Approved\": approved\n","})\n","\n","# Step 5: Encode Race feature\n","X = df_loan[[\"Income\", \"CreditScore\"]]\n","X[\"Race\"] = (df_loan[\"Race\"] == \"White\").astype(int)  # Encode White as 1, Black as 0\n","y = df_loan[\"Approved\"]\n","\n","# Step 6: Split data into train and test\n","X_train, X_test, y_train, y_test, race_train, race_test = train_test_split(\n","    X, y, df_loan[\"Race\"], test_size=0.3, random_state=42\n",")\n","\n","# Step 7: Train baseline Decision Tree model\n","dt_model = DecisionTreeClassifier(max_depth=5)\n","dt_model.fit(X_train, y_train)\n","y_pred_dt = dt_model.predict(X_test)\n","\n","# Step 8: Evaluate baseline accuracy and fairness\n","baseline_accuracy_dt = accuracy_score(y_test, y_pred_dt)\n","baseline_fairness_dt = equalized_odds_difference(y_test, y_pred_dt, sensitive_features=race_test)\n","\n","print(f\"Baseline Accuracy (Decision Tree): {baseline_accuracy_dt:.2f}\")\n","print(f\"Baseline Equalized Odds Difference: {baseline_fairness_dt:.2f}\")\n","\n","# Step 9: Simulated Adversarial Debiasing (structure only)\n","# Note: Real adversarial debiasing is complex; we simulate for the portfolio\n","# Here, we imagine retraining with bias mitigation (can be replaced with real technique)\n","# For now, simulate by modifying predictions slightly\n","y_pred_fair_dt = y_pred_dt.copy()\n","\n","# Simulate fairness adjustment (for demo purposes, flip some biased predictions)\n","bias_indices = (race_test == \"Black\") & (y_pred_dt == 0)\n","y_pred_fair_dt[bias_indices] = np.random.choice([0, 1], size=bias_indices.sum(), p=[0.4, 0.6])\n","\n","# Step 10: Evaluate mitigated model\n","fair_accuracy_dt = accuracy_score(y_test, y_pred_fair_dt)\n","fair_fairness_dt = equalized_odds_difference(y_test, y_pred_fair_dt, sensitive_features=race_test)\n","\n","print(f\"\\nFair Model Accuracy (Decision Tree): {fair_accuracy_dt:.2f}\")\n","print(f\"Fair Model Equalized Odds Difference: {fair_fairness_dt:.2f}\")\n"]}]}